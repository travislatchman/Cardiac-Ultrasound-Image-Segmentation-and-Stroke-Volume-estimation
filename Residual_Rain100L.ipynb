{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/travislatchman/Cardiac-Ultrasound-Image-Segmentation-and-Stroke-Volume-estimation/blob/main/Residual_Rain100L.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPJgjZf5nqAG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import Lambda\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from torchviz import make_dot\n",
        "\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBVfApbbnozj",
        "outputId": "4c00c386-996a-46b6-f55b-ac575796cfe1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11.7\n",
            "GPU Available:  True\n",
            "GPU is available.\n"
          ]
        }
      ],
      "source": [
        "print(torch.version.cuda)\n",
        "\n",
        "print(\"GPU Available: \", torch.cuda.is_available())\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU is available.\")\n",
        "else:\n",
        "    print(\"GPU is not available.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLuUqpxKnqAY"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41B5oZZqnqAZ"
      },
      "source": [
        "##### Construct Rain100L Dataset - Load both Rainy and Norainy images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvZTo3fHnqAi"
      },
      "outputs": [],
      "source": [
        "class Rain100L_Dataset(Dataset):\n",
        "    \"\"\"A custom dataset class for the Rain100L dataset.\n",
        "\n",
        "    This class inherits from the PyTorch Dataset class and\n",
        "    is used to load and transform rainy and non-rainy images\n",
        "    from the Rain100L dataset.\n",
        "\n",
        "    Attributes:\n",
        "        rainy_path (str): The path to the directory containing the rainy images.\n",
        "        norainy_path (str): The path to the directory containing the non-rainy images.\n",
        "        data (list): A list of tuples containing the filenames of the rainy and non-rainy images.\n",
        "        transform (callable, optional): An optional transform to apply to both rainy and non-rainy images.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, rainy_path, norainy_path, data, transform=None):\n",
        "        \"\"\"Initialize the Rain100L_Dataset.\n",
        "\n",
        "        Args:\n",
        "            rainy_path (str): The path to the directory containing the rainy images.\n",
        "            norainy_path (str): The path to the directory containing the non-rainy images.\n",
        "            data (list): A list of tuples containing the filenames of the rainy and non-rainy images.\n",
        "            transform (callable, optional): An optional transform to apply to both rainy and non-rainy images.\n",
        "        \"\"\"\n",
        "        self.rainy_path = rainy_path\n",
        "        self.norainy_path = norainy_path\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        \"\"\"Return the number of samples in the dataset.\n",
        "\n",
        "        Returns:\n",
        "            int: The number of samples in the dataset.\n",
        "        \"\"\"\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Get the rainy and non-rainy images at the given index.\n",
        "\n",
        "        Args:\n",
        "            idx (int): The index of the sample to get.\n",
        "\n",
        "        Returns:\n",
        "            tuple: A tuple containing the rainy and non-rainy images (PIL.Image.Image) at the given index.\n",
        "        \"\"\"\n",
        "        rainy_img_name, norainy_img_name = self.data[idx]\n",
        "        rainy_image = Image.open(os.path.join(self.rainy_path, rainy_img_name))\n",
        "        norainy_image = Image.open(os.path.join(self.norainy_path, norainy_img_name))\n",
        "\n",
        "        if self.transform:\n",
        "            rainy_image = self.transform(rainy_image)\n",
        "            norainy_image = self.transform(norainy_image)\n",
        "\n",
        "        return rainy_image, norainy_image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uULWou2gnqAj"
      },
      "source": [
        "##### First implementation idea for splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmdCETptnqAk"
      },
      "outputs": [],
      "source": [
        "def split_data(rainy_path, norainy_path, train_ratio=0.7, val_ratio=0.2, test_ratio=0.1):\n",
        "    \"\"\"Split the rainy and non-rainy image files into train, validation, and test sets.\n",
        "\n",
        "    The function takes the paths to the directories containing rainy and non-rainy images,\n",
        "    and returns three lists of tuples (rainy_image, non_rainy_image) for train, validation, and test sets.\n",
        "\n",
        "    Args:\n",
        "        rainy_path (str): The path to the directory containing the rainy images.\n",
        "        norainy_path (str): The path to the directory containing the non-rainy images.\n",
        "        train_ratio (float, optional): The ratio of samples to use for the training set. Default is 0.7.\n",
        "        val_ratio (float, optional): The ratio of samples to use for the validation set. Default is 0.2.\n",
        "        test_ratio (float, optional): The ratio of samples to use for the test set. Default is 0.1.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing three lists of tuples (rainy_image, non_rainy_image) for train, validation, and test sets.\n",
        "    \"\"\"\n",
        "    # Set a random seed\n",
        "    random.seed(42)\n",
        "\n",
        "    rainy_files = sorted(os.listdir(rainy_path))\n",
        "    norainy_files = sorted(os.listdir(norainy_path))\n",
        "    \n",
        "    data_size = len(rainy_files)\n",
        "    indices = list(range(data_size))\n",
        "    random.shuffle(indices)\n",
        "\n",
        "    train_indices = indices[:int(data_size * train_ratio)]\n",
        "    val_indices = indices[int(data_size * train_ratio):int(data_size * (train_ratio + val_ratio))]\n",
        "    test_indices = indices[int(data_size * (train_ratio + val_ratio)):]\n",
        "\n",
        "    train_data = [(rainy_files[i], norainy_files[i]) for i in train_indices]\n",
        "    val_data = [(rainy_files[i], norainy_files[i]) for i in val_indices]\n",
        "    test_data = [(rainy_files[i], norainy_files[i]) for i in test_indices]\n",
        "\n",
        "    return train_data, val_data, test_data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8CuUmfDnqAk"
      },
      "source": [
        "### Split the data and create data loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38kOhxKenqAk"
      },
      "outputs": [],
      "source": [
        "def resize_and_pad(target_width, target_height):\n",
        "    \"\"\"Create a function that resizes and pads an image to the specified dimensions.\n",
        "\n",
        "    This function generates a new function that takes an image as input and returns a\n",
        "    new image with the specified target width and height, preserving its aspect ratio,\n",
        "    and padding the shorter sides with black pixels if needed.\n",
        "\n",
        "    Args:\n",
        "        target_width (int): The target width of the output image.\n",
        "        target_height (int): The target height of the output image.\n",
        "\n",
        "    Returns:\n",
        "        function: A function that takes an image as input and returns a new image\n",
        "                  with the specified target width and height.\n",
        "    \"\"\"\n",
        "    def _resize_and_pad(image):\n",
        "        aspect_ratio = image.width / image.height\n",
        "        if aspect_ratio > 1:  # width > height\n",
        "            new_width = target_width\n",
        "            new_height = int(new_width / aspect_ratio)\n",
        "        else:  # height >= width\n",
        "            new_height = target_height\n",
        "            new_width = int(new_height * aspect_ratio)\n",
        "\n",
        "        resized_image = image.resize((new_width, new_height), Image.BICUBIC)\n",
        "\n",
        "        padded_image = Image.new('RGB', (target_width, target_height), color=0)\n",
        "        left_padding = (target_width - new_width) // 2\n",
        "        top_padding = (target_height - new_height) // 2\n",
        "        padded_image.paste(resized_image, (left_padding, top_padding))\n",
        "        return padded_image\n",
        "\n",
        "    return _resize_and_pad\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Db1qVzanqAl"
      },
      "outputs": [],
      "source": [
        "rainy_path = r\"G:\\\\My Drive\\Deraining\\\\Rain100L\\\\rainy\"\n",
        "norainy_path = r\"G:\\\\My Drive\\\\Deraining\\\\Rain100L\"\n",
        "\n",
        "\n",
        "train_data, val_data, test_data = split_data(rainy_path, norainy_path)\n",
        "\n",
        "target_width = 480\n",
        "target_height = 320\n",
        "transform = transforms.Compose([\n",
        "    Lambda(resize_and_pad(target_width, target_height)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_set = Rain100L_Dataset(rainy_path, norainy_path, train_data, transform)\n",
        "val_set = Rain100L_Dataset(rainy_path, norainy_path, val_data, transform)\n",
        "test_set = Rain100L_Dataset(rainy_path, norainy_path, test_data, transform)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=4, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=4, shuffle=False)\n",
        "test_loader = DataLoader(test_set, batch_size=4, shuffle=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rE4PBJInnqAm"
      },
      "source": [
        "### Residual U-Net Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BeeYBbFEnqAm"
      },
      "outputs": [],
      "source": [
        "class UNet(nn.Module):\n",
        "    \"\"\"U-Net architecture with residual blocks for image segmentation tasks.\n",
        "\n",
        "    Args:\n",
        "        in_channels (int): Number of input channels.\n",
        "        out_channels (int): Number of output channels.\n",
        "\n",
        "    Attributes:\n",
        "        enc1, enc2, enc3, enc4 (ResidualBlock): Encoder blocks with residual connections.\n",
        "        pool (nn.MaxPool2d): Max pooling layer.\n",
        "        middle (ResidualBlock): Middle block with residual connections.\n",
        "        up4, up3, up2, up1 (nn.Sequential): Decoder up-sampling blocks.\n",
        "        dec4, dec3, dec2, dec1 (ResidualBlock): Decoder blocks with residual connections.\n",
        "        output (nn.Conv2d): Convolutional layer for output prediction.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        def conv_block(in_channels, out_channels):\n",
        "            return ResidualBlock(in_channels, out_channels)\n",
        "\n",
        "        class ResidualBlock(nn.Module):\n",
        "            \"\"\"Residual Block module to be used within a convolutional neural network.\n",
        "\n",
        "            Args:\n",
        "                in_channels (int): Number of input channels.\n",
        "                out_channels (int): Number of output channels.\n",
        "\n",
        "            Attributes:\n",
        "                conv1 (nn.Conv2d): First convolutional layer.\n",
        "                relu1 (nn.ReLU): First ReLU activation layer.\n",
        "                conv2 (nn.Conv2d): Second convolutional layer.\n",
        "                relu2 (nn.ReLU): Second ReLU activation layer.\n",
        "                conv_skip (nn.Conv2d, optional): Convolutional layer for the skip connection.\n",
        "            \"\"\"\n",
        "            def __init__(self, in_channels, out_channels):\n",
        "                super(ResidualBlock, self).__init__()\n",
        "                self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "                self.relu1 = nn.ReLU(inplace=True)\n",
        "                self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "                self.relu2 = nn.ReLU(inplace=True)\n",
        "\n",
        "                if in_channels != out_channels:\n",
        "                    self.conv_skip = nn.Conv2d(in_channels, out_channels, kernel_size=1, padding=0)\n",
        "                else:\n",
        "                    self.conv_skip = None\n",
        "\n",
        "            def forward(self, x):\n",
        "                identity = x\n",
        "                out = self.relu1(self.conv1(x))\n",
        "                out = self.conv2(out)\n",
        "\n",
        "                if self.conv_skip is not None:\n",
        "                    identity = self.conv_skip(identity)\n",
        "\n",
        "                out += identity\n",
        "                out = self.relu2(out)\n",
        "                return out\n",
        "\n",
        "        def up_block(in_channels, out_channels):\n",
        "            return nn.Sequential(\n",
        "                nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2),\n",
        "                nn.ReLU(inplace=True)\n",
        "            )\n",
        "\n",
        "        self.enc1 = conv_block(in_channels, 64)\n",
        "        self.enc2 = conv_block(64, 128)\n",
        "        self.enc3 = conv_block(128, 256)\n",
        "        self.enc4 = conv_block(256, 512)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        \n",
        "        self.middle = conv_block(512, 1024)\n",
        "\n",
        "        self.up4 = up_block(1024, 512)\n",
        "        self.dec4 = conv_block(1024, 512)\n",
        "        self.up3 = up_block(512, 256)\n",
        "        self.dec3 = conv_block(512, 256)\n",
        "        self.up2 = up_block(256, 128)\n",
        "        self.dec2 = conv_block(256, 128)\n",
        "\n",
        "        self.up1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
        "        self.dec1 = conv_block(128, 64)\n",
        "\n",
        "        self.output = nn.Conv2d(64, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc1 = self.enc1(x)\n",
        "        enc2 = self.enc2(self.pool(enc1))\n",
        "        enc3 = self.enc3(self.pool(enc2))\n",
        "        enc4 = self.enc4(self.pool(enc3))\n",
        "\n",
        "        middle = self.middle(self.pool(enc4))\n",
        "\n",
        "        up4 = self.up4(middle)\n",
        "        merge4 = torch.cat([enc4, up4], dim=1)\n",
        "        dec4 = self.dec4(merge4)\n",
        "\n",
        "        up3 = self.up3(dec4)\n",
        "        merge3 = torch.cat([enc3, up3], dim=1)\n",
        "        dec3 = self.dec3(merge3)\n",
        "\n",
        "        up2 = self.up2(dec3)\n",
        "        merge2 = torch.cat([enc2, up2], dim=1)\n",
        "        dec2 = self.dec2(merge2)\n",
        "\n",
        "        up1 = self.up1(dec2)\n",
        "        merge1 = torch.cat([enc1, up1], dim=1)\n",
        "        dec1 = self.dec1(merge1)\n",
        "\n",
        "        output = self.output(dec1)\n",
        "        return output\n",
        "\n",
        "unet = UNet(3, 3)  # Adjust input and output channels to 3 for RGB images\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caMKMtvfnqAp"
      },
      "source": [
        "### Visualization in PyTorch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOhykSAnnqAq",
        "outputId": "10dcd54a-5532-4aec-df3a-0401da1fa0e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'unet_residual.png'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a dummy input tensor with the same shape as your input data\n",
        "dummy_input = torch.randn(1, 3, 480, 320)  # Adjust the shape as needed\n",
        "\n",
        "# Move the model and dummy input to the device (either GPU or CPU)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "unet = UNet(3, 3).to(device)\n",
        "dummy_input = dummy_input.to(device)\n",
        "\n",
        "# Run the model with the dummy input and visualize the model architecture\n",
        "output = unet(dummy_input)\n",
        "dot = make_dot(output, params=dict(unet.named_parameters()))\n",
        "dot.format = 'png'\n",
        "dot.render('unet_residual')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XED8swKLnqAs"
      },
      "source": [
        "### Visualization in Netron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wACG49AXnqAs",
        "outputId": "b7104b3c-2499-4e12-bd6e-3632e073eb31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================ Diagnostic Run torch.onnx.export version 2.0.0 ================\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch.onnx\n",
        "\n",
        "dummy_input = torch.randn(1, 3, 480, 320)\n",
        "dummy_input = dummy_input.to(device)\n",
        "\n",
        "torch.onnx.export(unet, dummy_input, \"unet_residual.onnx\", opset_version=11)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUxdIA-KnqAt"
      },
      "source": [
        "##### To train, validate, and test the U-Net model on the Rain100L dataset \n",
        "1. Prepare the dataset and split it into training, validation, and test sets. \n",
        "2. Create the dataset loader for training, validation, and test sets.\n",
        "3. Train the model on the training set and validate on the validation set.\n",
        "4. Test the model on the test set, compute the evaluation metrics (PSNR and SSIM), and save the derained images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrO7UHJGnqAt"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "unet = UNet(3, 3).to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(unet.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J58nR9i_nqAu",
        "outputId": "4bf1f20d-f3ea-4f55-90e6-69574a55ef3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Training starts! ---\n",
            "Epoch 1/200 - Train loss: 0.875453, Val loss: 1.388509\n",
            "Epoch 1 - Training time: 7.8529 seconds, Validation time: 0.9062 seconds\n",
            "Epoch 2/200 - Train loss: 0.686874, Val loss: 0.136586\n",
            "Epoch 2 - Training time: 4.9332 seconds, Validation time: 0.8655 seconds\n",
            "Epoch 3/200 - Train loss: 0.127534, Val loss: 0.096754\n",
            "Epoch 3 - Training time: 4.9695 seconds, Validation time: 0.8774 seconds\n",
            "Epoch 4/200 - Train loss: 0.067627, Val loss: 0.035560\n",
            "Epoch 4 - Training time: 4.9360 seconds, Validation time: 0.8696 seconds\n",
            "Epoch 5/200 - Train loss: 0.027988, Val loss: 0.023630\n",
            "Epoch 5 - Training time: 5.1064 seconds, Validation time: 0.8764 seconds\n",
            "Epoch 6/200 - Train loss: 0.018896, Val loss: 0.013395\n",
            "Epoch 6 - Training time: 5.0683 seconds, Validation time: 0.8767 seconds\n",
            "Epoch 7/200 - Train loss: 0.013205, Val loss: 0.017039\n",
            "Epoch 7 - Training time: 5.1058 seconds, Validation time: 0.8722 seconds\n",
            "Epoch 8/200 - Train loss: 0.011826, Val loss: 0.010023\n",
            "Epoch 8 - Training time: 5.0351 seconds, Validation time: 0.8885 seconds\n",
            "Epoch 9/200 - Train loss: 0.009102, Val loss: 0.008943\n",
            "Epoch 9 - Training time: 5.2163 seconds, Validation time: 0.9622 seconds\n",
            "Epoch 10/200 - Train loss: 0.007696, Val loss: 0.008346\n",
            "Epoch 10 - Training time: 5.1238 seconds, Validation time: 0.8642 seconds\n",
            "Epoch 11/200 - Train loss: 0.006655, Val loss: 0.007109\n",
            "Epoch 11 - Training time: 5.1088 seconds, Validation time: 0.8971 seconds\n",
            "Epoch 12/200 - Train loss: 0.005563, Val loss: 0.005499\n",
            "Epoch 12 - Training time: 5.0965 seconds, Validation time: 0.8807 seconds\n",
            "Epoch 13/200 - Train loss: 0.004916, Val loss: 0.005726\n",
            "Epoch 13 - Training time: 5.0647 seconds, Validation time: 0.9122 seconds\n",
            "Epoch 14/200 - Train loss: 0.004236, Val loss: 0.005152\n",
            "Epoch 14 - Training time: 5.1409 seconds, Validation time: 0.8802 seconds\n",
            "Epoch 15/200 - Train loss: 0.004056, Val loss: 0.004917\n",
            "Epoch 15 - Training time: 5.0343 seconds, Validation time: 0.8792 seconds\n",
            "Epoch 16/200 - Train loss: 0.003757, Val loss: 0.004494\n",
            "Epoch 16 - Training time: 5.0253 seconds, Validation time: 0.8647 seconds\n",
            "Epoch 17/200 - Train loss: 0.003568, Val loss: 0.004222\n",
            "Epoch 17 - Training time: 5.0426 seconds, Validation time: 0.8932 seconds\n",
            "Epoch 18/200 - Train loss: 0.003346, Val loss: 0.004131\n",
            "Epoch 18 - Training time: 4.9949 seconds, Validation time: 0.8492 seconds\n",
            "Epoch 19/200 - Train loss: 0.003148, Val loss: 0.003883\n",
            "Epoch 19 - Training time: 4.9214 seconds, Validation time: 0.8542 seconds\n",
            "Epoch 20/200 - Train loss: 0.003096, Val loss: 0.003727\n",
            "Epoch 20 - Training time: 4.9442 seconds, Validation time: 0.8582 seconds\n",
            "Epoch 21/200 - Train loss: 0.002884, Val loss: 0.003628\n",
            "Epoch 21 - Training time: 4.9436 seconds, Validation time: 0.8567 seconds\n",
            "Epoch 22/200 - Train loss: 0.002773, Val loss: 0.003539\n",
            "Epoch 22 - Training time: 4.9751 seconds, Validation time: 0.8532 seconds\n",
            "Epoch 23/200 - Train loss: 0.002648, Val loss: 0.003272\n",
            "Epoch 23 - Training time: 4.9354 seconds, Validation time: 0.8602 seconds\n",
            "Epoch 24/200 - Train loss: 0.002629, Val loss: 0.003232\n",
            "Epoch 24 - Training time: 4.9826 seconds, Validation time: 0.8676 seconds\n",
            "Epoch 25/200 - Train loss: 0.002488, Val loss: 0.003086\n",
            "Epoch 25 - Training time: 4.9561 seconds, Validation time: 0.8677 seconds\n",
            "Epoch 26/200 - Train loss: 0.002383, Val loss: 0.002954\n",
            "Epoch 26 - Training time: 4.9371 seconds, Validation time: 0.8602 seconds\n",
            "Epoch 27/200 - Train loss: 0.002259, Val loss: 0.002915\n",
            "Epoch 27 - Training time: 4.9561 seconds, Validation time: 0.8521 seconds\n",
            "Epoch 28/200 - Train loss: 0.002239, Val loss: 0.002844\n",
            "Epoch 28 - Training time: 5.0115 seconds, Validation time: 0.8682 seconds\n",
            "Epoch 29/200 - Train loss: 0.002188, Val loss: 0.002900\n",
            "Epoch 29 - Training time: 4.9741 seconds, Validation time: 0.8682 seconds\n",
            "Epoch 30/200 - Train loss: 0.002180, Val loss: 0.003055\n",
            "Epoch 30 - Training time: 4.9841 seconds, Validation time: 0.8675 seconds\n",
            "Epoch 31/200 - Train loss: 0.002160, Val loss: 0.002762\n",
            "Epoch 31 - Training time: 5.0276 seconds, Validation time: 0.8902 seconds\n",
            "Epoch 32/200 - Train loss: 0.002130, Val loss: 0.002667\n",
            "Epoch 32 - Training time: 5.6220 seconds, Validation time: 1.0473 seconds\n",
            "Epoch 33/200 - Train loss: 0.002025, Val loss: 0.002661\n",
            "Epoch 33 - Training time: 4.9964 seconds, Validation time: 0.8562 seconds\n",
            "Epoch 34/200 - Train loss: 0.002053, Val loss: 0.002542\n",
            "Epoch 34 - Training time: 5.0137 seconds, Validation time: 0.8622 seconds\n",
            "Epoch 35/200 - Train loss: 0.001947, Val loss: 0.002637\n",
            "Epoch 35 - Training time: 4.9669 seconds, Validation time: 0.8692 seconds\n",
            "Epoch 36/200 - Train loss: 0.001851, Val loss: 0.002439\n",
            "Epoch 36 - Training time: 4.9848 seconds, Validation time: 0.8692 seconds\n",
            "Epoch 37/200 - Train loss: 0.001813, Val loss: 0.002372\n",
            "Epoch 37 - Training time: 4.9976 seconds, Validation time: 0.8672 seconds\n",
            "Epoch 38/200 - Train loss: 0.001832, Val loss: 0.002339\n",
            "Epoch 38 - Training time: 4.9866 seconds, Validation time: 0.8723 seconds\n",
            "Epoch 39/200 - Train loss: 0.001923, Val loss: 0.002275\n",
            "Epoch 39 - Training time: 4.9987 seconds, Validation time: 0.8736 seconds\n",
            "Epoch 40/200 - Train loss: 0.001848, Val loss: 0.002396\n",
            "Epoch 40 - Training time: 5.0361 seconds, Validation time: 0.8727 seconds\n",
            "Epoch 41/200 - Train loss: 0.001892, Val loss: 0.002471\n",
            "Epoch 41 - Training time: 4.9976 seconds, Validation time: 0.8712 seconds\n",
            "Epoch 42/200 - Train loss: 0.001907, Val loss: 0.002220\n",
            "Epoch 42 - Training time: 5.0212 seconds, Validation time: 0.8712 seconds\n",
            "Epoch 43/200 - Train loss: 0.001843, Val loss: 0.002358\n",
            "Epoch 43 - Training time: 5.0052 seconds, Validation time: 0.8792 seconds\n",
            "Epoch 44/200 - Train loss: 0.001730, Val loss: 0.002351\n",
            "Epoch 44 - Training time: 4.9964 seconds, Validation time: 0.8633 seconds\n",
            "Epoch 45/200 - Train loss: 0.001761, Val loss: 0.002422\n",
            "Epoch 45 - Training time: 5.0357 seconds, Validation time: 0.8682 seconds\n",
            "Epoch 46/200 - Train loss: 0.001780, Val loss: 0.002061\n",
            "Epoch 46 - Training time: 5.0171 seconds, Validation time: 0.8742 seconds\n",
            "Epoch 47/200 - Train loss: 0.001628, Val loss: 0.002061\n",
            "Epoch 47 - Training time: 5.0292 seconds, Validation time: 0.8682 seconds\n",
            "Epoch 48/200 - Train loss: 0.001552, Val loss: 0.002000\n",
            "Epoch 48 - Training time: 5.0072 seconds, Validation time: 0.8711 seconds\n",
            "Epoch 49/200 - Train loss: 0.001519, Val loss: 0.001883\n",
            "Epoch 49 - Training time: 5.0403 seconds, Validation time: 0.8652 seconds\n",
            "Epoch 50/200 - Train loss: 0.001466, Val loss: 0.001824\n",
            "Epoch 50 - Training time: 5.0040 seconds, Validation time: 0.8666 seconds\n",
            "Epoch 51/200 - Train loss: 0.001423, Val loss: 0.001829\n",
            "Epoch 51 - Training time: 4.9857 seconds, Validation time: 0.8642 seconds\n",
            "Epoch 52/200 - Train loss: 0.001336, Val loss: 0.001780\n",
            "Epoch 52 - Training time: 5.0081 seconds, Validation time: 0.8672 seconds\n",
            "Epoch 53/200 - Train loss: 0.001326, Val loss: 0.001761\n",
            "Epoch 53 - Training time: 5.0182 seconds, Validation time: 0.8636 seconds\n",
            "Epoch 54/200 - Train loss: 0.001348, Val loss: 0.001756\n",
            "Epoch 54 - Training time: 5.0677 seconds, Validation time: 0.8742 seconds\n",
            "Epoch 55/200 - Train loss: 0.001314, Val loss: 0.001704\n",
            "Epoch 55 - Training time: 5.0577 seconds, Validation time: 0.8742 seconds\n",
            "Epoch 56/200 - Train loss: 0.001270, Val loss: 0.001644\n",
            "Epoch 56 - Training time: 5.0292 seconds, Validation time: 0.8692 seconds\n",
            "Epoch 57/200 - Train loss: 0.001251, Val loss: 0.001774\n",
            "Epoch 57 - Training time: 5.0060 seconds, Validation time: 0.8723 seconds\n",
            "Epoch 58/200 - Train loss: 0.001299, Val loss: 0.001689\n",
            "Epoch 58 - Training time: 5.0216 seconds, Validation time: 0.8694 seconds\n",
            "Epoch 59/200 - Train loss: 0.001347, Val loss: 0.001639\n",
            "Epoch 59 - Training time: 4.9855 seconds, Validation time: 0.8752 seconds\n",
            "Epoch 60/200 - Train loss: 0.001251, Val loss: 0.001581\n",
            "Epoch 60 - Training time: 5.0131 seconds, Validation time: 0.8804 seconds\n",
            "Epoch 61/200 - Train loss: 0.001245, Val loss: 0.001739\n",
            "Epoch 61 - Training time: 5.0112 seconds, Validation time: 0.8672 seconds\n",
            "Epoch 62/200 - Train loss: 0.001240, Val loss: 0.001632\n",
            "Epoch 62 - Training time: 4.9939 seconds, Validation time: 0.8679 seconds\n",
            "Epoch 63/200 - Train loss: 0.001145, Val loss: 0.001542\n",
            "Epoch 63 - Training time: 5.0054 seconds, Validation time: 0.8667 seconds\n",
            "Epoch 64/200 - Train loss: 0.001135, Val loss: 0.001525\n",
            "Epoch 64 - Training time: 4.9870 seconds, Validation time: 0.8705 seconds\n",
            "Epoch 65/200 - Train loss: 0.001167, Val loss: 0.001540\n",
            "Epoch 65 - Training time: 5.0148 seconds, Validation time: 0.8642 seconds\n",
            "Epoch 66/200 - Train loss: 0.001128, Val loss: 0.001545\n",
            "Epoch 66 - Training time: 5.0094 seconds, Validation time: 0.8672 seconds\n",
            "Epoch 67/200 - Train loss: 0.001102, Val loss: 0.001625\n",
            "Epoch 67 - Training time: 5.0266 seconds, Validation time: 0.8662 seconds\n",
            "Epoch 68/200 - Train loss: 0.001077, Val loss: 0.001409\n",
            "Epoch 68 - Training time: 5.0068 seconds, Validation time: 0.8668 seconds\n",
            "Epoch 69/200 - Train loss: 0.001077, Val loss: 0.001568\n",
            "Epoch 69 - Training time: 5.0360 seconds, Validation time: 0.8702 seconds\n",
            "Epoch 70/200 - Train loss: 0.001052, Val loss: 0.001393\n",
            "Epoch 70 - Training time: 5.0343 seconds, Validation time: 0.8693 seconds\n",
            "Epoch 71/200 - Train loss: 0.001073, Val loss: 0.001460\n",
            "Epoch 71 - Training time: 5.0177 seconds, Validation time: 0.8722 seconds\n",
            "Epoch 72/200 - Train loss: 0.001031, Val loss: 0.001432\n",
            "Epoch 72 - Training time: 4.9987 seconds, Validation time: 0.8757 seconds\n",
            "Epoch 73/200 - Train loss: 0.000992, Val loss: 0.001356\n",
            "Epoch 73 - Training time: 4.9788 seconds, Validation time: 0.8648 seconds\n",
            "Epoch 74/200 - Train loss: 0.001081, Val loss: 0.001665\n",
            "Epoch 74 - Training time: 4.9808 seconds, Validation time: 0.8764 seconds\n",
            "Epoch 75/200 - Train loss: 0.001084, Val loss: 0.001423\n",
            "Epoch 75 - Training time: 5.0163 seconds, Validation time: 0.8672 seconds\n",
            "Epoch 76/200 - Train loss: 0.001007, Val loss: 0.001400\n",
            "Epoch 76 - Training time: 4.9962 seconds, Validation time: 0.8731 seconds\n",
            "Epoch 77/200 - Train loss: 0.001024, Val loss: 0.001309\n",
            "Epoch 77 - Training time: 5.0121 seconds, Validation time: 0.8703 seconds\n",
            "Epoch 78/200 - Train loss: 0.000983, Val loss: 0.001344\n",
            "Epoch 78 - Training time: 4.9811 seconds, Validation time: 0.8703 seconds\n",
            "Epoch 79/200 - Train loss: 0.000948, Val loss: 0.001420\n",
            "Epoch 79 - Training time: 5.0563 seconds, Validation time: 0.8702 seconds\n",
            "Epoch 80/200 - Train loss: 0.000946, Val loss: 0.001270\n",
            "Epoch 80 - Training time: 5.0122 seconds, Validation time: 0.8686 seconds\n",
            "Epoch 81/200 - Train loss: 0.000970, Val loss: 0.001320\n",
            "Epoch 81 - Training time: 4.9998 seconds, Validation time: 0.8701 seconds\n",
            "Epoch 82/200 - Train loss: 0.000935, Val loss: 0.001333\n",
            "Epoch 82 - Training time: 4.9854 seconds, Validation time: 0.8702 seconds\n",
            "Epoch 83/200 - Train loss: 0.001063, Val loss: 0.001223\n",
            "Epoch 83 - Training time: 5.0093 seconds, Validation time: 0.8658 seconds\n",
            "Epoch 84/200 - Train loss: 0.000949, Val loss: 0.001349\n",
            "Epoch 84 - Training time: 5.0134 seconds, Validation time: 0.8712 seconds\n",
            "Epoch 85/200 - Train loss: 0.000923, Val loss: 0.001248\n",
            "Epoch 85 - Training time: 5.0156 seconds, Validation time: 0.8632 seconds\n",
            "Epoch 86/200 - Train loss: 0.000919, Val loss: 0.001240\n",
            "Epoch 86 - Training time: 5.0001 seconds, Validation time: 0.8704 seconds\n",
            "Epoch 87/200 - Train loss: 0.000967, Val loss: 0.001884\n",
            "Epoch 87 - Training time: 5.0008 seconds, Validation time: 0.8742 seconds\n",
            "Epoch 88/200 - Train loss: 0.001047, Val loss: 0.001448\n",
            "Epoch 88 - Training time: 5.0299 seconds, Validation time: 0.8663 seconds\n",
            "Epoch 89/200 - Train loss: 0.001117, Val loss: 0.001855\n",
            "Epoch 89 - Training time: 5.0170 seconds, Validation time: 0.8702 seconds\n",
            "Epoch 90/200 - Train loss: 0.001100, Val loss: 0.001641\n",
            "Epoch 90 - Training time: 4.9889 seconds, Validation time: 0.8695 seconds\n",
            "Epoch 91/200 - Train loss: 0.001117, Val loss: 0.001510\n",
            "Epoch 91 - Training time: 5.0196 seconds, Validation time: 0.8732 seconds\n",
            "Epoch 92/200 - Train loss: 0.000984, Val loss: 0.001507\n",
            "Epoch 92 - Training time: 5.0090 seconds, Validation time: 0.8662 seconds\n",
            "Epoch 93/200 - Train loss: 0.000923, Val loss: 0.001304\n",
            "Epoch 93 - Training time: 5.0277 seconds, Validation time: 0.8756 seconds\n",
            "Epoch 94/200 - Train loss: 0.000922, Val loss: 0.001354\n",
            "Epoch 94 - Training time: 5.0167 seconds, Validation time: 0.8662 seconds\n",
            "Epoch 95/200 - Train loss: 0.000975, Val loss: 0.001192\n",
            "Epoch 95 - Training time: 4.9920 seconds, Validation time: 0.8722 seconds\n",
            "Epoch 96/200 - Train loss: 0.000889, Val loss: 0.001205\n",
            "Epoch 96 - Training time: 4.9953 seconds, Validation time: 0.8672 seconds\n",
            "Epoch 97/200 - Train loss: 0.000869, Val loss: 0.001177\n",
            "Epoch 97 - Training time: 5.0202 seconds, Validation time: 0.8730 seconds\n",
            "Epoch 98/200 - Train loss: 0.000851, Val loss: 0.001153\n",
            "Epoch 98 - Training time: 5.0119 seconds, Validation time: 0.8684 seconds\n",
            "Epoch 99/200 - Train loss: 0.000829, Val loss: 0.001150\n",
            "Epoch 99 - Training time: 5.0142 seconds, Validation time: 0.8712 seconds\n",
            "Epoch 100/200 - Train loss: 0.000795, Val loss: 0.001212\n",
            "Epoch 100 - Training time: 5.0000 seconds, Validation time: 0.8773 seconds\n",
            "Epoch 101/200 - Train loss: 0.000816, Val loss: 0.001164\n",
            "Epoch 101 - Training time: 5.0231 seconds, Validation time: 0.8713 seconds\n",
            "Epoch 102/200 - Train loss: 0.000793, Val loss: 0.001113\n",
            "Epoch 102 - Training time: 5.0106 seconds, Validation time: 0.8725 seconds\n",
            "Epoch 103/200 - Train loss: 0.000809, Val loss: 0.001296\n",
            "Epoch 103 - Training time: 5.0114 seconds, Validation time: 0.8723 seconds\n",
            "Epoch 104/200 - Train loss: 0.000850, Val loss: 0.001184\n",
            "Epoch 104 - Training time: 5.0163 seconds, Validation time: 0.8712 seconds\n",
            "Epoch 105/200 - Train loss: 0.000879, Val loss: 0.001118\n",
            "Epoch 105 - Training time: 5.0040 seconds, Validation time: 0.8952 seconds\n",
            "Epoch 106/200 - Train loss: 0.000888, Val loss: 0.001316\n",
            "Epoch 106 - Training time: 5.0483 seconds, Validation time: 0.8733 seconds\n",
            "Epoch 107/200 - Train loss: 0.000845, Val loss: 0.001161\n",
            "Epoch 107 - Training time: 5.0257 seconds, Validation time: 0.8696 seconds\n",
            "Epoch 108/200 - Train loss: 0.000811, Val loss: 0.001235\n",
            "Epoch 108 - Training time: 5.0162 seconds, Validation time: 0.8734 seconds\n",
            "Epoch 109/200 - Train loss: 0.000791, Val loss: 0.001112\n",
            "Epoch 109 - Training time: 5.0382 seconds, Validation time: 0.8712 seconds\n",
            "Epoch 110/200 - Train loss: 0.000776, Val loss: 0.001112\n",
            "Epoch 110 - Training time: 4.9934 seconds, Validation time: 0.8682 seconds\n",
            "Epoch 111/200 - Train loss: 0.000759, Val loss: 0.001123\n",
            "Epoch 111 - Training time: 5.0456 seconds, Validation time: 0.8871 seconds\n",
            "Epoch 112/200 - Train loss: 0.000762, Val loss: 0.001169\n",
            "Epoch 112 - Training time: 5.0456 seconds, Validation time: 0.8722 seconds\n",
            "Epoch 113/200 - Train loss: 0.000772, Val loss: 0.001072\n",
            "Epoch 113 - Training time: 5.0264 seconds, Validation time: 0.8715 seconds\n",
            "Epoch 114/200 - Train loss: 0.000790, Val loss: 0.001049\n",
            "Epoch 114 - Training time: 5.0406 seconds, Validation time: 0.8682 seconds\n",
            "Epoch 115/200 - Train loss: 0.000794, Val loss: 0.001389\n",
            "Epoch 115 - Training time: 5.0450 seconds, Validation time: 0.8923 seconds\n",
            "Epoch 116/200 - Train loss: 0.000788, Val loss: 0.001209\n",
            "Epoch 116 - Training time: 5.0829 seconds, Validation time: 0.9022 seconds\n",
            "Epoch 117/200 - Train loss: 0.000758, Val loss: 0.001054\n",
            "Epoch 117 - Training time: 5.0456 seconds, Validation time: 0.8713 seconds\n",
            "Epoch 118/200 - Train loss: 0.000733, Val loss: 0.001108\n",
            "Epoch 118 - Training time: 4.9898 seconds, Validation time: 0.8692 seconds\n",
            "Epoch 119/200 - Train loss: 0.000723, Val loss: 0.001081\n",
            "Epoch 119 - Training time: 4.9969 seconds, Validation time: 0.8667 seconds\n",
            "Epoch 120/200 - Train loss: 0.000718, Val loss: 0.001032\n",
            "Epoch 120 - Training time: 4.9931 seconds, Validation time: 0.8652 seconds\n",
            "Epoch 121/200 - Train loss: 0.000704, Val loss: 0.001012\n",
            "Epoch 121 - Training time: 5.0275 seconds, Validation time: 0.8677 seconds\n",
            "Epoch 122/200 - Train loss: 0.000703, Val loss: 0.001163\n",
            "Epoch 122 - Training time: 5.0178 seconds, Validation time: 0.8645 seconds\n",
            "Epoch 123/200 - Train loss: 0.000714, Val loss: 0.001061\n",
            "Epoch 123 - Training time: 4.9986 seconds, Validation time: 0.8735 seconds\n",
            "Epoch 124/200 - Train loss: 0.000730, Val loss: 0.001061\n",
            "Epoch 124 - Training time: 5.0005 seconds, Validation time: 0.8714 seconds\n",
            "Epoch 125/200 - Train loss: 0.000698, Val loss: 0.001083\n",
            "Epoch 125 - Training time: 5.0044 seconds, Validation time: 0.8672 seconds\n",
            "Epoch 126/200 - Train loss: 0.000776, Val loss: 0.001321\n",
            "Epoch 126 - Training time: 5.0106 seconds, Validation time: 0.8727 seconds\n",
            "Epoch 127/200 - Train loss: 0.000817, Val loss: 0.001164\n",
            "Epoch 127 - Training time: 5.0117 seconds, Validation time: 0.8692 seconds\n",
            "Epoch 128/200 - Train loss: 0.000758, Val loss: 0.001062\n",
            "Epoch 128 - Training time: 5.0269 seconds, Validation time: 0.8675 seconds\n",
            "Epoch 129/200 - Train loss: 0.000706, Val loss: 0.001090\n",
            "Epoch 129 - Training time: 5.0109 seconds, Validation time: 0.8682 seconds\n",
            "Epoch 130/200 - Train loss: 0.000702, Val loss: 0.001019\n",
            "Epoch 130 - Training time: 5.0030 seconds, Validation time: 0.8692 seconds\n",
            "Epoch 131/200 - Train loss: 0.000689, Val loss: 0.001006\n",
            "Epoch 131 - Training time: 5.0154 seconds, Validation time: 0.8662 seconds\n",
            "Epoch 132/200 - Train loss: 0.000682, Val loss: 0.001052\n",
            "Epoch 132 - Training time: 5.0147 seconds, Validation time: 0.8634 seconds\n",
            "Epoch 133/200 - Train loss: 0.000676, Val loss: 0.001080\n",
            "Epoch 133 - Training time: 4.9895 seconds, Validation time: 0.8693 seconds\n",
            "Epoch 134/200 - Train loss: 0.000740, Val loss: 0.001076\n",
            "Epoch 134 - Training time: 4.9923 seconds, Validation time: 0.8692 seconds\n",
            "Epoch 135/200 - Train loss: 0.000749, Val loss: 0.001131\n",
            "Epoch 135 - Training time: 5.0233 seconds, Validation time: 0.8734 seconds\n",
            "Epoch 136/200 - Train loss: 0.000724, Val loss: 0.001002\n",
            "Epoch 136 - Training time: 4.9835 seconds, Validation time: 0.8652 seconds\n",
            "Epoch 137/200 - Train loss: 0.000674, Val loss: 0.000999\n",
            "Epoch 137 - Training time: 5.0336 seconds, Validation time: 0.8724 seconds\n",
            "Epoch 138/200 - Train loss: 0.000679, Val loss: 0.001031\n",
            "Epoch 138 - Training time: 5.0314 seconds, Validation time: 0.8682 seconds\n",
            "Epoch 139/200 - Train loss: 0.000642, Val loss: 0.000981\n",
            "Epoch 139 - Training time: 5.0126 seconds, Validation time: 0.8649 seconds\n",
            "Epoch 140/200 - Train loss: 0.000631, Val loss: 0.000964\n",
            "Epoch 140 - Training time: 5.0246 seconds, Validation time: 0.8764 seconds\n",
            "Epoch 141/200 - Train loss: 0.000619, Val loss: 0.001009\n",
            "Epoch 141 - Training time: 5.0085 seconds, Validation time: 0.8844 seconds\n",
            "Epoch 142/200 - Train loss: 0.000629, Val loss: 0.001063\n",
            "Epoch 142 - Training time: 5.0136 seconds, Validation time: 0.8752 seconds\n",
            "Epoch 143/200 - Train loss: 0.000654, Val loss: 0.001000\n",
            "Epoch 143 - Training time: 5.0329 seconds, Validation time: 0.8685 seconds\n",
            "Epoch 144/200 - Train loss: 0.000672, Val loss: 0.001039\n",
            "Epoch 144 - Training time: 4.9884 seconds, Validation time: 0.8673 seconds\n",
            "Epoch 145/200 - Train loss: 0.000631, Val loss: 0.001046\n",
            "Epoch 145 - Training time: 5.0128 seconds, Validation time: 0.8722 seconds\n",
            "Epoch 146/200 - Train loss: 0.000622, Val loss: 0.001013\n",
            "Epoch 146 - Training time: 4.9863 seconds, Validation time: 0.8832 seconds\n",
            "Epoch 147/200 - Train loss: 0.000606, Val loss: 0.000998\n",
            "Epoch 147 - Training time: 4.9878 seconds, Validation time: 0.8633 seconds\n",
            "Epoch 148/200 - Train loss: 0.000617, Val loss: 0.001089\n",
            "Epoch 148 - Training time: 4.9761 seconds, Validation time: 0.8685 seconds\n",
            "Epoch 149/200 - Train loss: 0.000663, Val loss: 0.000959\n",
            "Epoch 149 - Training time: 5.0155 seconds, Validation time: 0.8612 seconds\n",
            "Epoch 150/200 - Train loss: 0.000630, Val loss: 0.001176\n",
            "Epoch 150 - Training time: 5.0176 seconds, Validation time: 0.8669 seconds\n",
            "Epoch 151/200 - Train loss: 0.000653, Val loss: 0.000958\n",
            "Epoch 151 - Training time: 4.9667 seconds, Validation time: 0.8612 seconds\n",
            "Epoch 152/200 - Train loss: 0.000605, Val loss: 0.000950\n",
            "Epoch 152 - Training time: 5.0141 seconds, Validation time: 0.8642 seconds\n",
            "Epoch 153/200 - Train loss: 0.000576, Val loss: 0.000965\n",
            "Epoch 153 - Training time: 4.9853 seconds, Validation time: 0.8712 seconds\n",
            "Epoch 154/200 - Train loss: 0.000603, Val loss: 0.000999\n",
            "Epoch 154 - Training time: 4.9989 seconds, Validation time: 0.8613 seconds\n",
            "Epoch 155/200 - Train loss: 0.000644, Val loss: 0.001172\n",
            "Epoch 155 - Training time: 4.9692 seconds, Validation time: 0.8672 seconds\n",
            "Epoch 156/200 - Train loss: 0.000646, Val loss: 0.001094\n",
            "Epoch 156 - Training time: 5.0197 seconds, Validation time: 0.8602 seconds\n",
            "Epoch 157/200 - Train loss: 0.000657, Val loss: 0.001011\n",
            "Epoch 157 - Training time: 4.9932 seconds, Validation time: 1.4813 seconds\n",
            "Epoch 158/200 - Train loss: 0.000648, Val loss: 0.001082\n",
            "Epoch 158 - Training time: 5.0226 seconds, Validation time: 0.8602 seconds\n",
            "Epoch 159/200 - Train loss: 0.000706, Val loss: 0.000945\n",
            "Epoch 159 - Training time: 4.9667 seconds, Validation time: 0.8676 seconds\n",
            "Epoch 160/200 - Train loss: 0.000645, Val loss: 0.001151\n",
            "Epoch 160 - Training time: 4.9804 seconds, Validation time: 0.8624 seconds\n",
            "Epoch 161/200 - Train loss: 0.000609, Val loss: 0.001084\n",
            "Epoch 161 - Training time: 4.9999 seconds, Validation time: 0.8673 seconds\n",
            "Epoch 162/200 - Train loss: 0.000596, Val loss: 0.000951\n",
            "Epoch 162 - Training time: 5.0347 seconds, Validation time: 0.8682 seconds\n",
            "Epoch 163/200 - Train loss: 0.000540, Val loss: 0.000939\n",
            "Epoch 163 - Training time: 4.9897 seconds, Validation time: 0.8663 seconds\n",
            "Epoch 164/200 - Train loss: 0.000562, Val loss: 0.000967\n",
            "Epoch 164 - Training time: 4.9883 seconds, Validation time: 0.8632 seconds\n",
            "Epoch 165/200 - Train loss: 0.000533, Val loss: 0.000923\n",
            "Epoch 165 - Training time: 4.9328 seconds, Validation time: 0.8612 seconds\n",
            "Epoch 166/200 - Train loss: 0.000527, Val loss: 0.000983\n",
            "Epoch 166 - Training time: 4.9831 seconds, Validation time: 0.8714 seconds\n",
            "Epoch 167/200 - Train loss: 0.000526, Val loss: 0.000963\n",
            "Epoch 167 - Training time: 4.9970 seconds, Validation time: 0.8698 seconds\n",
            "Epoch 168/200 - Train loss: 0.000517, Val loss: 0.001043\n",
            "Epoch 168 - Training time: 5.0308 seconds, Validation time: 0.8692 seconds\n",
            "Epoch 169/200 - Train loss: 0.000529, Val loss: 0.000946\n",
            "Epoch 169 - Training time: 5.0179 seconds, Validation time: 0.8632 seconds\n",
            "Epoch 170/200 - Train loss: 0.000509, Val loss: 0.000925\n",
            "Epoch 170 - Training time: 5.0088 seconds, Validation time: 0.8632 seconds\n",
            "Epoch 171/200 - Train loss: 0.000524, Val loss: 0.000952\n",
            "Epoch 171 - Training time: 4.9938 seconds, Validation time: 0.8432 seconds\n",
            "Epoch 172/200 - Train loss: 0.000500, Val loss: 0.001016\n",
            "Epoch 172 - Training time: 5.1330 seconds, Validation time: 0.9018 seconds\n",
            "Epoch 173/200 - Train loss: 0.000508, Val loss: 0.000957\n",
            "Epoch 173 - Training time: 5.1551 seconds, Validation time: 0.8752 seconds\n",
            "Epoch 174/200 - Train loss: 0.000508, Val loss: 0.000936\n",
            "Epoch 174 - Training time: 5.0098 seconds, Validation time: 0.8700 seconds\n",
            "Epoch 175/200 - Train loss: 0.000537, Val loss: 0.001042\n",
            "Epoch 175 - Training time: 5.0424 seconds, Validation time: 0.8638 seconds\n",
            "Epoch 176/200 - Train loss: 0.000510, Val loss: 0.001029\n",
            "Epoch 176 - Training time: 4.9904 seconds, Validation time: 0.8643 seconds\n",
            "Epoch 177/200 - Train loss: 0.000478, Val loss: 0.000975\n",
            "Epoch 177 - Training time: 4.9949 seconds, Validation time: 0.8663 seconds\n",
            "Epoch 178/200 - Train loss: 0.000471, Val loss: 0.000965\n",
            "Epoch 178 - Training time: 4.9940 seconds, Validation time: 0.8716 seconds\n",
            "Epoch 179/200 - Train loss: 0.000455, Val loss: 0.000966\n",
            "Epoch 179 - Training time: 5.0085 seconds, Validation time: 0.8642 seconds\n",
            "Epoch 180/200 - Train loss: 0.000455, Val loss: 0.000950\n",
            "Epoch 180 - Training time: 5.0289 seconds, Validation time: 0.8682 seconds\n",
            "Epoch 181/200 - Train loss: 0.000449, Val loss: 0.000956\n",
            "Epoch 181 - Training time: 5.0500 seconds, Validation time: 0.8675 seconds\n",
            "Epoch 182/200 - Train loss: 0.000459, Val loss: 0.000976\n",
            "Epoch 182 - Training time: 5.0135 seconds, Validation time: 0.8694 seconds\n",
            "Epoch 183/200 - Train loss: 0.000453, Val loss: 0.000971\n",
            "Epoch 183 - Training time: 5.0143 seconds, Validation time: 0.8742 seconds\n",
            "Epoch 184/200 - Train loss: 0.000442, Val loss: 0.001151\n",
            "Epoch 184 - Training time: 5.0040 seconds, Validation time: 0.8740 seconds\n",
            "Epoch 185/200 - Train loss: 0.000449, Val loss: 0.000978\n",
            "Epoch 185 - Training time: 5.9498 seconds, Validation time: 0.8714 seconds\n",
            "Epoch 186/200 - Train loss: 0.000440, Val loss: 0.000949\n",
            "Epoch 186 - Training time: 5.0067 seconds, Validation time: 0.8654 seconds\n",
            "Epoch 187/200 - Train loss: 0.000425, Val loss: 0.000958\n",
            "Epoch 187 - Training time: 5.0337 seconds, Validation time: 0.8728 seconds\n",
            "Epoch 188/200 - Train loss: 0.000424, Val loss: 0.000932\n",
            "Epoch 188 - Training time: 5.0081 seconds, Validation time: 0.8694 seconds\n",
            "Epoch 189/200 - Train loss: 0.000446, Val loss: 0.001269\n",
            "Epoch 189 - Training time: 4.9976 seconds, Validation time: 0.8746 seconds\n",
            "Epoch 190/200 - Train loss: 0.000496, Val loss: 0.001007\n",
            "Epoch 190 - Training time: 4.9731 seconds, Validation time: 0.8699 seconds\n",
            "Epoch 191/200 - Train loss: 0.000457, Val loss: 0.000934\n",
            "Epoch 191 - Training time: 4.9821 seconds, Validation time: 0.8702 seconds\n",
            "Epoch 192/200 - Train loss: 0.000483, Val loss: 0.001193\n",
            "Epoch 192 - Training time: 5.0192 seconds, Validation time: 0.8728 seconds\n",
            "Epoch 193/200 - Train loss: 0.000523, Val loss: 0.000915\n",
            "Epoch 193 - Training time: 5.0212 seconds, Validation time: 0.8678 seconds\n",
            "Epoch 194/200 - Train loss: 0.000524, Val loss: 0.001052\n",
            "Epoch 194 - Training time: 5.0063 seconds, Validation time: 0.8611 seconds\n",
            "Epoch 195/200 - Train loss: 0.000540, Val loss: 0.001147\n",
            "Epoch 195 - Training time: 5.0079 seconds, Validation time: 0.8652 seconds\n",
            "Epoch 196/200 - Train loss: 0.000566, Val loss: 0.000967\n",
            "Epoch 196 - Training time: 5.0012 seconds, Validation time: 0.8658 seconds\n",
            "Epoch 197/200 - Train loss: 0.000476, Val loss: 0.001015\n",
            "Epoch 197 - Training time: 4.9903 seconds, Validation time: 0.8722 seconds\n",
            "Epoch 198/200 - Train loss: 0.000450, Val loss: 0.000936\n",
            "Epoch 198 - Training time: 5.0216 seconds, Validation time: 0.8732 seconds\n",
            "Epoch 199/200 - Train loss: 0.000448, Val loss: 0.000986\n",
            "Epoch 199 - Training time: 5.0771 seconds, Validation time: 0.8843 seconds\n",
            "Epoch 200/200 - Train loss: 0.000437, Val loss: 0.001034\n",
            "Epoch 200 - Training time: 5.0665 seconds, Validation time: 0.8795 seconds\n",
            "Training time: 1182.0595 seconds\n"
          ]
        }
      ],
      "source": [
        "# Initialize gradient scaler for mixed-precision training\n",
        "scaler = GradScaler()\n",
        "accumulation_steps = 4\n",
        "\n",
        "# Initialize lists to store train and validation losses\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "print('--- Training starts! ---')\n",
        "start_time_train = time.time()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    unet.train()\n",
        "    train_loss = 0.0\n",
        "\n",
        "    start_time_train_epoch = time.time()\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    for step, (rain, norain) in enumerate(train_loader):\n",
        "        rain = rain.to(device)\n",
        "        norain = norain.to(device)\n",
        "\n",
        "        # Use autocast for mixed-precision training\n",
        "        with autocast():\n",
        "            output = unet(rain)\n",
        "            loss = criterion(output, norain)\n",
        "        \n",
        "        # Scale the loss and backpropagate\n",
        "        scaler.scale(loss).backward()\n",
        "        \n",
        "        if (step + 1) % accumulation_steps == 0:\n",
        "            # Update the model weights and optimizer state\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad()\n",
        "        \n",
        "        train_loss += loss.item()\n",
        "    \n",
        "    # Calculate the average loss for the epoch and append it to the list\n",
        "    train_losses.append(train_loss/len(train_loader))\n",
        "\n",
        "    end_time_train_epoch = time.time() - start_time_train_epoch\n",
        "    \n",
        "    unet.eval()\n",
        "    val_loss = 0.0\n",
        "    \n",
        "    start_time_val_epoch = time.time()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for rain, norain in val_loader:\n",
        "            rain = rain.to(device)\n",
        "            norain = norain.to(device)\n",
        "\n",
        "            with autocast():\n",
        "                output = unet(rain)\n",
        "                loss = criterion(output, norain)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    val_losses.append(val_loss/len(val_loader))\n",
        "    end_time_val_epoch = time.time() - start_time_val_epoch\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - Train loss: {train_losses[-1]:.6f}, Val loss: {val_losses[-1]:.6f}\")\n",
        "    print(f\"Epoch {epoch+1} - Training time: {end_time_train_epoch:.4f} seconds, Validation time: {end_time_val_epoch:.4f} seconds\")\n",
        "\n",
        "end_time_train = time.time() - start_time_train\n",
        "print('Training time: {0:.4f} seconds'.format(end_time_train))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1khPhCG5nqAu",
        "outputId": "7ba9a8cc-0504-4e45-eea3-562d2897cf95"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure()\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Train and Validation Loss per Epoch')\n",
        "plt.savefig('train_val_loss_plot.png')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fmq4zD0jnqAz",
        "outputId": "59676310-4241-4ac7-8d49-e65b6334b6b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Testing starts! ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\labuser\\AppData\\Local\\Temp\\ipykernel_13276\\1426726481.py:29: FutureWarning: `multichannel` is a deprecated argument name for `structural_similarity`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
            "  cur_ssim = ssim(norain[j], output[j], data_range=1, multichannel=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average PSNR: 33.174186 (std: 1.710238), Average SSIM: 0.933454 (std: 0.039085)\n"
          ]
        }
      ],
      "source": [
        "# Test the model and save derained images\n",
        "print('--- Testing starts! ---')\n",
        "start_time_test = time.time()\n",
        "\n",
        "unet.eval()\n",
        "test_psnr = 0.0\n",
        "test_ssim = 0.0\n",
        "output_path = \"G:\\My Drive\\Deraining\\Rain100L\\derained\"\n",
        "if not os.path.exists(output_path):\n",
        "    os.makedirs(output_path)\n",
        "metrics = []\n",
        "with torch.no_grad():\n",
        "    img_count = 1\n",
        "    for i, (rain, norain) in enumerate(test_loader):\n",
        "        rain = rain.to(device)\n",
        "        norain = norain.to(device)\n",
        "\n",
        "        output = unet(rain)\n",
        "        output = output.cpu().numpy().transpose((0, 2, 3, 1)).clip(0, 1)\n",
        "        norain = norain.cpu().numpy().transpose((0, 2, 3, 1)).clip(0, 1)\n",
        "\n",
        "        for j in range(output.shape[0]):\n",
        "            # Save the derained image\n",
        "            output_img = Image.fromarray((output[j] * 255).astype(np.uint8))\n",
        "            output_img.save(os.path.join(output_path, f\"derained_{img_count}.png\"))\n",
        "\n",
        "            # Compute PSNR and SSIM\n",
        "            cur_psnr = psnr(norain[j], output[j], data_range=1)\n",
        "            cur_ssim = ssim(norain[j], output[j], data_range=1, multichannel=True)\n",
        "\n",
        "            metrics.append([cur_psnr, cur_ssim])\n",
        "            img_count += 1\n",
        "\n",
        "# Save the metrics to a CSV file and compute the average and standard deviation\n",
        "metrics_df = pd.DataFrame(metrics, columns=[\"PSNR\", \"SSIM\"])\n",
        "metrics_df.to_csv(\"metrics.csv\", index=False)\n",
        "\n",
        "mean_psnr = metrics_df[\"PSNR\"].mean()\n",
        "mean_ssim = metrics_df[\"SSIM\"].mean()\n",
        "std_psnr = metrics_df[\"PSNR\"].std()\n",
        "std_ssim = metrics_df[\"SSIM\"].std()\n",
        "\n",
        "print(f\"Average PSNR: {mean_psnr:.6f} (std: {std_psnr:.6f}), Average SSIM: {mean_ssim:.6f} (std: {std_ssim:.6f})\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}