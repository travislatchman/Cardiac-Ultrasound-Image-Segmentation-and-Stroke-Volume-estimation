{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJaQxUwYxdzgUDaITRGcQg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/travislatchman/Cardiac-Ultrasound-Image-Segmentation-and-Stroke-Volume-estimation/blob/main/Cardiac_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DssSiQkLn1s"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import scipy.signal as signal\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### example placeholder for an audio file"
      ],
      "metadata": {
        "id": "kEaZyoK8Lvqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load audio file\n",
        "file_path = \".wav file here\"\n",
        "audio_signal, sample_rate = librosa.load(file_path, sr=None)"
      ],
      "metadata": {
        "id": "I_Lrx9VNLtwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions from my audio project"
      ],
      "metadata": {
        "id": "O6F27Yo_MLtC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def noise_reduction(audio_signal, sample_rate, noise_window_duration=0.5):\n",
        "    window_size = sample_rate // 10\n",
        "    overlap = window_size // 2\n",
        "    noise_window_size = int(noise_window_duration * sample_rate)\n",
        "\n",
        "    # Calculate the spectrogram of the input signal\n",
        "    _, _, stft = signal.stft(audio_signal, fs=sample_rate, nperseg=window_size, noverlap=overlap)\n",
        "\n",
        "    # Calculate the average noise profile within the noise window\n",
        "    noise_profile = np.mean(np.abs(stft[:, :noise_window_size])**2, axis=1)\n",
        "    noise_profile = np.sqrt(noise_profile)\n",
        "\n",
        "    # Perform spectral subtraction to reduce noise\n",
        "    stft_noise_reduced = stft - noise_profile[:, np.newaxis]\n",
        "    stft_noise_reduced = np.maximum(stft_noise_reduced, 0)\n",
        "\n",
        "    # Compute the inverse STFT to obtain the denoised signal\n",
        "    _, denoised_signal = signal.istft(stft_noise_reduced, fs=sample_rate, nperseg=window_size, noverlap=overlap)\n",
        "\n",
        "    return denoised_signal"
      ],
      "metadata": {
        "id": "2pTYmXXVWOJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "denoised_signal = noise_reduction(audio_signal, sample_rate)"
      ],
      "metadata": {
        "id": "CV6LIZHXWXE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing\n",
        "def preprocess_audio(audio_signal, sample_rate):\n",
        "    # Noise reduction (spectral subtraction)\n",
        "    denoised_signal = noise_reduction(audio_signal, sample_rate)\n",
        "\n",
        "    # Normalize the audio signal\n",
        "    normalized_signal = librosa.util.normalize(denoised_signal)\n",
        "    return normalized_signal"
      ],
      "metadata": {
        "id": "Loiy4CQgL643"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_audio = preprocess_audio(audio_signal, sample_rate)"
      ],
      "metadata": {
        "id": "Lzu1A1oOL95j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Extraction\n",
        "def extract_features(audio_signal, sample_rate):\n",
        "    # Extract MFCCs\n",
        "    mfccs = librosa.feature.mfcc(audio_signal, sr=sample_rate)\n",
        "\n",
        "    # Extract spectral features\n",
        "    spectral_centroid = librosa.feature.spectral_centroid(audio_signal, sr=sample_rate)\n",
        "    spectral_flux = librosa.onset.onset_strength(audio_signal, sr=sample_rate)\n",
        "    spectral_rolloff = librosa.feature.spectral_rolloff(audio_signal, sr=sample_rate)\n",
        "\n",
        "    # Compute STFT\n",
        "    stft = librosa.stft(audio_signal)\n",
        "\n",
        "    # (Optional) Compute CWT\n",
        "    # cwt = signal.cwt(audio_signal, signal.ricker, np.arange(1, 31))\n",
        "\n",
        "    return mfccs, spectral_centroid, spectral_flux, spectral_rolloff, stft\n",
        "\n"
      ],
      "metadata": {
        "id": "e5bOGEGhMFzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# output - features that will be input to peak detection algorithm\n",
        "mfccs, spectral_centroid, spectral_flux, spectral_rolloff, stft = extract_features(audio_signal, sample_rate)"
      ],
      "metadata": {
        "id": "q7c_2ypYMI17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cardiac Specific (not sure if these work, but looking for S1 and S2 peaks, and then segmenting accordingly?)"
      ],
      "metadata": {
        "id": "l7n-eFt1MVOY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "made peak detection to use the extracted features from above"
      ],
      "metadata": {
        "id": "FrXp1_RbW34F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def peak_detection(audio_signal, sample_rate, features):\n",
        "    # Calculate the onset envelope\n",
        "    onset_env = librosa.onset.onset_strength(audio_signal, sr=sample_rate)\n",
        "\n",
        "    # Detect the peaks in the onset envelope\n",
        "    peaks, _ = audio_signal.find_peaks(onset_env, distance=sample_rate // 4)\n",
        "\n",
        "    # Separate the detected peaks into S1 and S2 sounds based on their amplitude\n",
        "    peak_amplitudes = onset_env[peaks]\n",
        "    median_amplitude = np.median(peak_amplitudes)\n",
        "\n",
        "    s1_locs = peaks[peak_amplitudes >= median_amplitude]\n",
        "    s2_locs = peaks[peak_amplitudes < median_amplitude]\n",
        "\n",
        "    return s1_locs, s2_locs"
      ],
      "metadata": {
        "id": "sRHAdUJANCSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s1_locs, s2_locs = peak_detection(audio_signal, sample_rate, (mfccs, spectral_centroid, spectral_flux, spectral_rolloff))"
      ],
      "metadata": {
        "id": "5dN42nmFNHI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"S1 locations:\", s1_locs)\n",
        "print(\"S2 locations:\", s2_locs)"
      ],
      "metadata": {
        "id": "_wgDcQZwNOVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def segmentation(audio_signal, s1_locs, s2_locs, sample_rate):\n",
        "    segments = []\n",
        "    s1_s2_pairs = zip(s1_locs, s2_locs)\n",
        "\n",
        "    for s1, s2 in s1_s2_pairs:\n",
        "        # Check if the next S1 location is in the list\n",
        "        next_s1_index = np.where(s1_locs == s1)[0][0] + 1\n",
        "        if next_s1_index < len(s1_locs):\n",
        "            next_s1 = s1_locs[next_s1_index]\n",
        "            cardiac_cycle = audio_signal[s1:next_s1]\n",
        "            segments.append(cardiac_cycle)\n",
        "    \n",
        "    return segments"
      ],
      "metadata": {
        "id": "duc8kenZNUEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "segments = segmentation(audio_signal, s1_locs, s2_locs, sample_rate)"
      ],
      "metadata": {
        "id": "4QhcYJkJMlEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of segments:\", len(segments))"
      ],
      "metadata": {
        "id": "JzqbdxM3Ng4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### To consider duration (modified cardiac functions from above) "
      ],
      "metadata": {
        "id": "08DRxbfppXt1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "modified peak detection for duration"
      ],
      "metadata": {
        "id": "Kzd3gZympjjX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cardiac_cycle_detection(audio_signal, sample_rate):\n",
        "    # Calculate the onset envelope\n",
        "    onset_env = librosa.onset.onset_strength(audio_signal, sr=sample_rate)\n",
        "\n",
        "    # Detect the peaks in the onset envelope\n",
        "    peaks, _ = signal.find_peaks(onset_env, distance=sample_rate // 4)\n",
        "\n",
        "    # Separate the detected peaks into S1 and S2 sounds based on their amplitude\n",
        "    peak_amplitudes = onset_env[peaks]\n",
        "    median_amplitude = np.median(peak_amplitudes)\n",
        "\n",
        "    s1_locs = peaks[peak_amplitudes >= median_amplitude]\n",
        "    s2_locs = peaks[peak_amplitudes < median_amplitude]\n",
        "\n",
        "    # Calculate the duration of cardiac cycles (using S1 locations)\n",
        "    cardiac_cycle_durations = np.diff(s1_locs)\n",
        "\n",
        "    return s1_locs, s2_locs, cardiac_cycle_durations"
      ],
      "metadata": {
        "id": "hPZbEKCOpW3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "modified segmentation to include clip length and hanning window"
      ],
      "metadata": {
        "id": "AfiHbFIXp62E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cardiac_cycle_segmentation(audio_signal, s1_locs, s2_locs, sample_rate, clip_duration=1):\n",
        "    clip_length = sample_rate * clip_duration\n",
        "    segments = []\n",
        "\n",
        "    for s1, s2 in zip(s1_locs, s2_locs):\n",
        "        # Check if the next S1 location is in the list\n",
        "        next_s1_index = np.where(s1_locs == s1)[0][0] + 1\n",
        "        if next_s1_index < len(s1_locs):\n",
        "            next_s1 = s1_locs[next_s1_index]\n",
        "\n",
        "            # Calculate the start and end positions of the 1-second audio clip\n",
        "            clip_start = s1\n",
        "            clip_end = min(s1 + clip_length, next_s1)\n",
        "\n",
        "            # Extract the audio clip\n",
        "            audio_clip = audio_signal[clip_start:clip_end]\n",
        "\n",
        "            # Apply a windowing function (e.g., Hanning) to minimize discontinuities\n",
        "            window = np.hanning(len(audio_clip))\n",
        "            audio_clip = audio_clip * window\n",
        "\n",
        "            segments.append(audio_clip)\n",
        "\n",
        "    return segments"
      ],
      "metadata": {
        "id": "735j9ro5pnH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s1_locs, s2_locs, cardiac_cycle_durations = cardiac_cycle_detection(audio_signal, sample_rate)\n",
        "segments = cardiac_cycle_segmentation(audio_signal, s1_locs, s2_locs, sample_rate)\n",
        "\n",
        "print(\"Number of segments:\", len(segments))"
      ],
      "metadata": {
        "id": "llPkIuAWp1QK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}